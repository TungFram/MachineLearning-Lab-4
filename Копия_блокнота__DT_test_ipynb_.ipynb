{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGClrhQA9SAk"
      },
      "source": [
        "# Деревья решений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veekMy8WRjBi"
      },
      "source": [
        "## Построение дерева"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYkVwAFiUHXj"
      },
      "source": [
        "Опишем жадный алгоритм построения бинарного дерева решений:\n",
        "1. Начинаем со всей обучающей выборки $X$, которую помещаем в корень $R_1$. \n",
        "2. Задаём функционал качества $Q(X, j, t)$ и критерий остановки. \n",
        "3. Запускаем построение из корня: $SplitNode(1, R_1)$\n",
        "\n",
        "Функция $SplitNode(m, R_m)$\n",
        "1. Если выполнен критерий остановки, то выход.\n",
        "2. Находим наилучший с точки зрения $Q$ предикат: $j, t$: $[x_j<t]$\n",
        "3. Помещаем предикат в вкршину и получаем с его помощью разбиение $X$ на две части: $R_{left} = \\lbrace x|x_j<t \\rbrace$ и $R_{right} = \\lbrace x|x_j \\geqslant t \\rbrace$\n",
        "4. Поместим $R_{left}$ и $R_{right}$ соответсвенно в левое и правое поддерево.\n",
        "5. Рекурсивно повторяем $SplitNode(left, R_{left})$ и $SplitNode(right, R_{right})$.\n",
        "\n",
        "В конце поставим в соответствие каждому листу ответ. Для задачи классификации - это самый частый среди объектов класс или вектор с долями классов (можно интерпретировать как вероятности):\n",
        "$$ c_v = \\arg \\max_{k\\in Y} \\sum_{(x_i,y_i) \\in R_v} [y_i=k]  $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P6FsdBog4Ai"
      },
      "source": [
        "## Функционал качества для деревьев решений\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VAKO0aykGBD"
      },
      "source": [
        "Энтропия Шеннона для системы с N возможными состояниями определяется по формуле:\n",
        "$$H = - \\sum_{i=0}^{N} p_i\\log_2p_i $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5582B-1Fn2bw"
      },
      "source": [
        "где $p_i$ – вероятности нахождения системы в $i$-ом состоянии. \n",
        "\n",
        "Это очень важное понятие теории информации, которое позволяет оценить количество информации (степень хаоса в системе). Чем выше энтропия, тем менее упорядочена система и наоборот. С помощью энтропии мы формализуем функционал качества для разделение выборки (для задачи классификации)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbcMUd7bvk05"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AdLxP9CowTm"
      },
      "source": [
        "Код для расчёта энтропии:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mT8Jq8Av2sM"
      },
      "source": [
        "def entropy(y):\n",
        "    \n",
        "    _, counts = np.unique(y, return_counts=True)\n",
        "\n",
        "    probabilities = counts / counts.sum()\n",
        "    entropy = sum(probabilities * -np.log2(probabilities))\n",
        "     \n",
        "    return entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk9etb2vo7fK"
      },
      "source": [
        "Здесь $y$ - это массив значений целевой переменной"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07TCw0USzLus"
      },
      "source": [
        "Энтропия – по сути степень хаоса (или неопределенности) в системе. Уменьшение энтропии называют приростом информации (information gain, IG).\n",
        "\n",
        "Обочначим $R_v$ - объекты, которые нужно разделить в помощью предиката в вершине $v$. Запишем формулу для расчёта информационного прироста:\n",
        "$$ Q = IG = H(R_v) - (H(R_{left})+H(R_{right}))$$\n",
        "\n",
        "На каждом шаге нам нужно максимизировать этот функционал качества. Как это делать? Например, так можно перебрать $t$ для выбранного $j$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trEWHDoXg_p9"
      },
      "source": [
        "Предыдущая версия формулы прироста информации слишком упрощена. В работе необходимо использовать более устойчивую формулу, которая учитывает не только энтропию подмножеств, но и их размер. \n",
        "\n",
        "$$ Q = IG = H(R_v) - \\Big (\\frac{|R_{left}|} {|R_{v}|} H(R_{left})+ \\frac{|R_{right}|} {|R_{v}|} H(R_{right})\\Big)$$\n",
        "\n",
        "где, $|R_{v}|$, $|R_{left}|$ и $|R_{right}|$ - количество элементов в соответствующих множествах."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xmN6V_N1xBr"
      },
      "source": [
        "\n",
        "### Задание 4.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWFHZScF2CBF"
      },
      "source": [
        "Реализуйте алгоритм построения дерева. Должны быть отдельные функции (методы) для расчёта энтропии (уже есть), для разделения узлов дерева (используйте, например, `pandas`), для подсчёта функционала качества $IG$, для выбора наилучшего разделения (с учетом признаков и порогов), для проверки критерия остановки.\n",
        "\n",
        "Для набора данных `iris` реализуйте алгоритм и минимум три из разными критерия остановки из перечисленных ниже:\n",
        "* максимальной глубины дерева = 5\n",
        "* минимального числа объектов в листе = 5\n",
        "* максимальное количество листьев в дереве = 5\n",
        "* purity (остановка, если все объекты в листе относятся к одному классу)\n",
        "\n",
        "Реализуйте функцию `predict` (на вход функции подаётся датафрейм с объектами)\n",
        "\n",
        "Оцените точность каждой модели с помощью метрики доля правильных ответов (`from sklearn.metrics import accuracy_score` или реализовать свою)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import deque\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "def entropy(y):\n",
        "    _, counts = np.unique(y, return_counts=True)\n",
        "\n",
        "    probabilities = counts / counts.sum()\n",
        "    entropy_val = sum(probabilities * -np.log2(probabilities))\n",
        "\n",
        "    return entropy_val\n",
        "  \n",
        "\n",
        "class Node(object):\n",
        "    def __init__(self, X=None, depth=0):\n",
        "        self.X = X\n",
        "        self.depth = depth\n",
        "        self.split_param = None\n",
        "        self.target_value = None\n",
        "        self.left_child = None\n",
        "        self.right_child = None\n",
        "\n",
        "    def target(self):\n",
        "        if self.target_value is None:\n",
        "            targets, counts = np.unique(self.X.iloc[:, -1], return_counts=True)\n",
        "            best_target = (-1, float('-inf'))\n",
        "            for target, prop in zip(targets, counts):\n",
        "                if prop > best_target[1]:\n",
        "                    best_target = (target, prop)\n",
        "            self.target_value = best_target[0]\n",
        "        return self.target_value\n",
        "\n",
        "\n",
        "class DecisionTreeClassifier(object):\n",
        "\n",
        "    def __init__(self, max_depth=-1, min_samples_leaf=1, max_leaf_nodes=-1, purity=False):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.max_leaf_nodes = max_leaf_nodes\n",
        "        self.purity = purity\n",
        "\n",
        "        self.root = Node()\n",
        "        self.size = 1\n",
        "        self.next_nodes = deque()\n",
        "\n",
        "    def split(self, X, j, t):\n",
        "        sample1 = X[X.iloc[:, j] < t]\n",
        "        sample2 = X[X.iloc[:, j] >= t]\n",
        "\n",
        "        return sample1, sample2\n",
        "\n",
        "    def calc_ig(self, r_v, r_left, r_right):\n",
        "        r_left_prop = len(r_left) / len(r_v)\n",
        "        r_right_prop = len(r_right) / len(r_v)\n",
        "        return entropy(r_v) - \\\n",
        "               (r_left_prop * entropy(r_left) + r_right_prop * entropy(r_right))\n",
        "\n",
        "    def find_best_split(self, X):\n",
        "        best_values = (float('-inf'), -1, -1)\n",
        "        param_n = X.shape[1] - 1\n",
        "        for j in range(param_n):\n",
        "            min_value = X.iloc[:, j].min()\n",
        "            max_value = X.iloc[:, j].max()\n",
        "            values = np.linspace(min_value, max_value, num=10)\n",
        "            for t in values:\n",
        "                r_left, r_right = self.split(X, j, t)\n",
        "                ig = self.calc_ig(X.iloc[:, -1], r_left.iloc[:, -1], r_right.iloc[:, -1])\n",
        "                if ig > best_values[0]:\n",
        "                    best_values = (ig, j, t)\n",
        "        return best_values[1], best_values[2]\n",
        "\n",
        "    def check_purity(self, X):\n",
        "        targets = np.unique(X)\n",
        "        return len(targets) == 1\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        X = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1))))\n",
        "        self.root.X = X\n",
        "        self.next_nodes.append(self.root)\n",
        "\n",
        "        while len(self.next_nodes) > 0:\n",
        "            cur_node = self.next_nodes.popleft()\n",
        "            if cur_node.depth == self.max_depth:\n",
        "                continue\n",
        "            if cur_node.X.shape[0] <= self.min_samples_leaf:\n",
        "                continue\n",
        "            if self.purity and self.check_purity(cur_node.X.iloc[:, -1]):\n",
        "                continue\n",
        "\n",
        "            j, t = self.find_best_split(cur_node.X)\n",
        "            cur_node.split_param = (j, t)\n",
        "            r_left, r_right = self.split(cur_node.X, j, t)\n",
        "\n",
        "            left_node = Node(r_left, cur_node.depth + 1)\n",
        "            cur_node.left_child = left_node\n",
        "            self.next_nodes.append(left_node)\n",
        "            self.size += 1\n",
        "            if self.size == self.max_leaf_nodes:\n",
        "                self.next_nodes.clear()\n",
        "                break\n",
        "\n",
        "            right_node = Node(r_right, cur_node.depth + 1)\n",
        "            cur_node.right_child = right_node\n",
        "            self.next_nodes.append(right_node)\n",
        "            self.size += 1\n",
        "            if self.size == self.max_leaf_nodes:\n",
        "                self.next_nodes.clear()\n",
        "                break\n",
        "\n",
        "    def calc_final_node(self, node):\n",
        "        if node.left_child is None and node.right_child is None:\n",
        "            node.target()\n",
        "\n",
        "        if node.left_child is not None:\n",
        "            self.calc_final_node(node.left_child)\n",
        "\n",
        "        if node.right_child is not None:\n",
        "            self.calc_final_node(node.right_child)\n",
        "\n",
        "    def get_target(self, obj, node):\n",
        "        if node.right_child is None and node.left_child is None:\n",
        "            return node.target()\n",
        "\n",
        "        j, t = node.split_param\n",
        "\n",
        "        if obj[j] >= t:\n",
        "            return self.get_target(obj, node.right_child)\n",
        "        else:\n",
        "            return self.get_target(obj, node.left_child)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        return [self.get_target(X_test[i, :], self.root) for i in range(len(X_test))]"
      ],
      "metadata": {
        "id": "J3m1jzJ8fkLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=0)\n",
        "\n",
        "tree = DecisionTreeClassifier(purity=True)\n",
        "tree.fit(X_train, y_train)\n",
        "print('Accuracy with purity -', accuracy_score(tree.predict(X_test), y_test))\n",
        "\n",
        "tree = DecisionTreeClassifier(max_depth=5)\n",
        "tree.fit(X_train, y_train)\n",
        "print('Accuracy with max depth 5 -', accuracy_score(tree.predict(X_test), y_test))\n",
        "\n",
        "tree = DecisionTreeClassifier(max_leaf_nodes=15)\n",
        "tree.fit(X_train, y_train)\n",
        "print('Accuracy with 15 leaf nodes -', accuracy_score(tree.predict(X_test), y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyi-xNYuf0pm",
        "outputId": "6fa02966-35c4-4a76-dc0c-d7f7d522b332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with purity - 0.8333333333333334\n",
            "Accuracy with max depth 5 - 0.8666666666666667\n",
            "Accuracy with 15 leaf nodes - 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkyCjLcy_CTM"
      },
      "source": [
        "##  Случайный лес"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fKZe1FyRgCa"
      },
      "source": [
        "Опишем алгоритм случайный лес (*random forest*) и попутно разберём основные идеи:\n",
        "\n",
        "1. Зададим $N$ - число деревьев в лесу.\n",
        "2. Для каждого $n$ из $N$ сгенерируем свою выборку $X_n$. Пусть $m$ - это количество объектов в $X$. При генерации каждой $X_n$ мы будем брать объекты $m$ раз с возвращением. То есть один и тот же объект может попасть в выборку несколько раз, а какие-то объекты не попадут. (Этот способ назвается бутстрап).\n",
        "3. По каждой $X_n$ построим решающее дерево $b_n$. Обычно стараются делать глубокие деревья. В качестве критериев остановки можно использовать `max_depth` или `min_samples_leaf` (например, пока в каждом листе не окажется по одному объекту). При каждом разбиении сначала выбирается $k$ (эвристика $k = \\sqrt d$, где $d$ - это число признаков объектов из выборки $X$) случайных признаков из исходных, и оптимальное разделение выборки ищется только среди них. Обратите внимание, что мы не выбрасываем оставшиеся признаки!\n",
        "4. Итоговый алгоритм будет представлять собой результат голосования (для классификации) и среднее арифметическое (для регрессии). Модификация алгоритма предполагает учёт весов каждого отдельного слабого алгоритма в ансамбле, но в этом особо нет смысла.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJBQ8lc0WyrN"
      },
      "source": [
        "### Задание 4.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y594Jn04ZTCm"
      },
      "source": [
        "В качестве набора данных используйте: https://www.kaggle.com/mathchi/churn-for-bank-customers\n",
        "\n",
        "Там есть описание и примеры работы с этими данными. Если кратко, речь идёт про задачу прогнозирования оттока клиентов. Есть данные о 10 тысячах клиентов банка, часть из которых больше не являются клиентами."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be_mLbdVW2oG"
      },
      "source": [
        "Используя либо свою реализацию, либо  `DecisionTreeClassifier` с разными настройками из `sklearn.tree` реализйте алгоритм \"случайный лес\". \n",
        "\n",
        "Найдите наилучшие гиперпараметры этого алгоритма: количество деревьев, критерий остановки, функционал качества, минимальное количество объектов в листьях и другие.\n",
        "\n",
        "Нельзя использовать готовую реализацию случайного леса из `sklearn`.\n",
        "\n",
        "В подобных задачах очень важна интерпретируемость алгоритма. Попытайтесь оценить информативность признаков, т.е. ответить а вопрос, значения каких признаков являются самыми важными индикаторами того, что банк потеряет клиента."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.base import BaseEstimator\n",
        "import numpy as np\n",
        "from random import randrange\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "class RandomForest(BaseEstimator):\n",
        "    estimators = list()\n",
        "\n",
        "    def __init__(self, base_estimator=DecisionTreeClassifier, max_features='sqrt',\n",
        "                 n_estimators=10, max_depth=None, min_samples_leaf=1, max_leaf_nodes=None, criterion='gini'):\n",
        "        self.base_estimator = base_estimator\n",
        "        self.max_features = max_features\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.max_leaf_nodes = max_leaf_nodes\n",
        "        self.criterion = criterion\n",
        "\n",
        "    def get_boostrap_sample(self, sample):\n",
        "        new_sample = np.empty([sample.shape[0], sample.shape[1]])\n",
        "        n_sample = sample.shape[0]\n",
        "        for i in range(n_sample):\n",
        "            index = randrange(n_sample)\n",
        "            new_sample[i] = sample[index]\n",
        "        return new_sample\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        for i in range(self.n_estimators):\n",
        "            Xy = np.hstack((X, y.reshape(-1, 1)))\n",
        "            new_Xy = self.get_boostrap_sample(Xy)\n",
        "            new_X_train, new_y_train = new_Xy[:, :-1], new_Xy[:, -1].flatten()\n",
        "            estimator = self.base_estimator(max_features=self.max_features, max_depth=self.max_depth,\n",
        "                                            min_samples_leaf=self.min_samples_leaf, max_leaf_nodes=self.max_leaf_nodes,\n",
        "                                            criterion=self.criterion)\n",
        "            estimator.fit(new_X_train, new_y_train)\n",
        "            self.estimators.append(estimator)\n",
        "        return self\n",
        "\n",
        "    def predict_obj(self, pred_obj):\n",
        "        values, counts = np.unique(pred_obj, return_counts=True)\n",
        "        ind = np.argmax(counts)\n",
        "        return values[ind]\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        predictions = np.array([estimator.predict(X_test) for estimator in self.estimators])\n",
        "        return [self.predict_obj(predictions[:, i]) for i in range(X_test.shape[0])]\n",
        "\n",
        "    def score(self, X_test, y_test):\n",
        "        pred_y = self.predict(X_test)\n",
        "        return accuracy_score(pred_y, y_test)\n",
        "\n",
        "    def get_params(self, deep=False):\n",
        "        return {'base_estimator': self.base_estimator,\n",
        "                'max_features': self.max_features,\n",
        "                'n_estimators': self.n_estimators,\n",
        "                'max_depth': self.max_depth,\n",
        "                'min_samples_leaf': self.min_samples_leaf,\n",
        "                'max_leaf_nodes': self.max_leaf_nodes,\n",
        "                'criterion': self.criterion}\n",
        "\n",
        "    def set_params(self, params):\n",
        "        for parameter, value in params:\n",
        "            setattr(self, parameter, value)\n",
        "        return self\n",
        "\n",
        "    def get_feature_informativeness(self, X, y):\n",
        "        informativeness_matrix = np.empty((self.n_estimators, X.shape[1]))\n",
        "        for i in range(self.n_estimators):\n",
        "            Xy = np.hstack((X, y.reshape(-1, 1)))\n",
        "            new_Xy = self.get_boostrap_sample(Xy)\n",
        "            new_X_train, new_y_train = new_Xy[:, :-1], new_Xy[:, -1].flatten()\n",
        "            estimator = self.base_estimator(max_features=self.max_features, max_depth=self.max_depth,\n",
        "                                            min_samples_leaf=self.min_samples_leaf, max_leaf_nodes=self.max_leaf_nodes,\n",
        "                                            criterion=self.criterion)\n",
        "            estimator.fit(new_X_train, new_y_train)\n",
        "            oob_Xy = np.array([obj for obj in Xy if not any(np.equal(new_Xy, obj).all(1))])\n",
        "            oob_X_test, oob_y_test = oob_Xy[:, :-1], oob_Xy[:, -1].flatten()\n",
        "            pred_y = estimator.predict(oob_X_test)\n",
        "            initial_q = accuracy_score(pred_y, oob_y_test)\n",
        "            for j in range(oob_X_test.shape[1]):\n",
        "                noise = np.array([randrange(-1000, 1000) for _ in range(oob_X_test.shape[0])])\n",
        "                oob_X_test_copy = oob_X_test.copy()\n",
        "                oob_X_test_copy[:, j] = noise\n",
        "                noise_pred_y = estimator.predict(oob_X_test_copy)\n",
        "                noise_q = accuracy_score(noise_pred_y, oob_y_test)\n",
        "                informativeness_matrix[i, j] = initial_q - noise_q\n",
        "        return np.mean(informativeness_matrix, axis=0).argsort()[::-1]\n",
        "\n",
        "\n",
        "import itertools as it\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "class GridSearch(object):\n",
        "    best_score_ = float(\"-inf\")\n",
        "    best_params_ = None\n",
        "\n",
        "    def __init__(self, checked_estimator, params, scoring, cv):\n",
        "        self.checked_estimator = checked_estimator\n",
        "        self.params = params\n",
        "        self.scoring = scoring\n",
        "        self.cv = cv\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        param_combs = [[list(el) for el in zip(self.params.keys(), comb)]\n",
        "                       for comb in it.product(*(self.params[key] for key in self.params.keys()))]\n",
        "        for params in param_combs:\n",
        "            estimator = self.checked_estimator()\n",
        "            estimator.set_params(params)\n",
        "            score = cross_val_score(estimator, X, y, scoring=self.scoring, cv=self.cv).mean()\n",
        "            if self.best_score_ < score:\n",
        "                self.best_score_ = score\n",
        "                self.best_params_ = params\n",
        "        return self\n",
        "\n"
      ],
      "metadata": {
        "id": "IX0Sm34xf3xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "download_link = \"https://storage.googleapis.com/kagglesdsdata/datasets/797699/1368540/churn.csv?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com/20221117/auto/storage/goog4_request&X-Goog-Date=20221117T213808Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=705a08a3c5cb36a8b699e825f587e9da89d39ec2e0fd277ad55e5b4a8e734910e3d0b4697622e4dce47742472f68a8e470eb209196fc777594de9d51102b38a198fa4e6dbd90c4cb0497d6e35ea0df4a2a4f5b405319b1df56925542df742282b26b98ccb4be57fb4a06b8ff04bbc794ba4ebf7750d56e45ea58e8de4491cb495615450e8273d4acef8ac7d05d0a382dd34c140169fef3baf1fb5f54ac21be3f2a3c967739f62ed9a5341c69a2af4d1ea2c8e52c9f5fd708ec62a81a73ad82ad4774b8981e6c73228a3cd46fc46534f6e71ea49d12bd8eae71bc81a93392e92bed415d139fa9d5e515d09dabdc9d04cfd5789c9af767d3cbc08ca071e48f1d6b\"\n",
        "churn = gdown.download(download_link, \"churn.csv\")\n",
        "\n",
        "df = pd.read_csv(churn)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "g5CPNdGPgDXQ",
        "outputId": "bcf130e0-b1f2-4b53-b2f0-e279fd8b2601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://storage.googleapis.com/kagglesdsdata/datasets/797699/1368540/churn.csv?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com/20221117/auto/storage/goog4_request&X-Goog-Date=20221117T213808Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=705a08a3c5cb36a8b699e825f587e9da89d39ec2e0fd277ad55e5b4a8e734910e3d0b4697622e4dce47742472f68a8e470eb209196fc777594de9d51102b38a198fa4e6dbd90c4cb0497d6e35ea0df4a2a4f5b405319b1df56925542df742282b26b98ccb4be57fb4a06b8ff04bbc794ba4ebf7750d56e45ea58e8de4491cb495615450e8273d4acef8ac7d05d0a382dd34c140169fef3baf1fb5f54ac21be3f2a3c967739f62ed9a5341c69a2af4d1ea2c8e52c9f5fd708ec62a81a73ad82ad4774b8981e6c73228a3cd46fc46534f6e71ea49d12bd8eae71bc81a93392e92bed415d139fa9d5e515d09dabdc9d04cfd5789c9af767d3cbc08ca071e48f1d6b\n",
            "To: /content/churn.csv\n",
            "100%|██████████| 685k/685k [00:00<00:00, 5.19MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
              "0          1    15634602  Hargrave          619    France  Female   42   \n",
              "1          2    15647311      Hill          608     Spain  Female   41   \n",
              "2          3    15619304      Onio          502    France  Female   42   \n",
              "3          4    15701354      Boni          699    France  Female   39   \n",
              "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
              "\n",
              "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0       2       0.00              1          1               1   \n",
              "1       1   83807.86              1          0               1   \n",
              "2       8  159660.80              3          1               0   \n",
              "3       1       0.00              2          0               0   \n",
              "4       2  125510.82              1          1               1   \n",
              "\n",
              "   EstimatedSalary  Exited  \n",
              "0        101348.88       1  \n",
              "1        112542.58       0  \n",
              "2        113931.57       1  \n",
              "3         93826.63       0  \n",
              "4         79084.10       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-850cd4e2-6052-44a5-a236-007361b5ea87\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-850cd4e2-6052-44a5-a236-007361b5ea87')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-850cd4e2-6052-44a5-a236-007361b5ea87 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-850cd4e2-6052-44a5-a236-007361b5ea87');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "При обучении модели не будем учитывать признаки RowNumber, CustomerId Surname, так как они не влияют на то, покинет ли клиент банк (являются по сути шумовыми)."
      ],
      "metadata": {
        "id": "M9ca-v1WgIdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_data = df[['Geography', 'Gender']]\n",
        "numertical_binary_data = df[\n",
        "    ['CreditScore',\n",
        "     'Age',\n",
        "     'Tenure',\n",
        "     'Balance',\n",
        "     'NumOfProducts',\n",
        "     'EstimatedSalary',\n",
        "     'HasCrCard',\n",
        "     'IsActiveMember']\n",
        "     ].to_numpy()\n",
        "\n",
        "y = df['Exited'].to_numpy()\n",
        "\n",
        "encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "categorical_data = encoder.fit_transform(categorical_data).toarray()\n",
        "\n",
        "X = np.hstack((numertical_binary_data, categorical_data))\n",
        "\n",
        "print(cross_val_score(RandomForest(), X, y, cv=3).mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy-QYtyJgJf3",
        "outputId": "82c2b903-fef4-42a3-9f6b-b04a3c50f312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9091061475673662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Найдем науличшие гиперпараметры с помощью grid search.\n",
        "forest_params = {'n_estimators': np.arange(1, 30, 5), \n",
        "                 'min_samples_leaf': np.arange(1, 20, 5),\n",
        "                 'criterion': ['gini','entropy'],\n",
        "                 'max_depth': np.arange(10, 40, 10)}\n",
        "\n",
        "forest_grid = GridSearch(RandomForest, forest_params, scoring='accuracy', cv=3)\n",
        "forest_grid.fit(X, y)\n",
        "print(forest_grid.best_score_)\n",
        "print(forest_grid.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhOYJY_-gWxF",
        "outputId": "51c42e51-1fc9-4ddf-a329-d53d8eabc7df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8894000077872214\n",
            "[['n_estimators', 11], ['min_samples_leaf', 6], ['criterion', 'gini'], ['max_depth', 20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "При следующих гиперпараметрах модель дает наибольшую точность:\n",
        "[\n",
        "  ['n_estimators', 1]\n",
        "  ['min_samples_leaf', 1]\n",
        "  ['criterion', 'gini']\n",
        "  ['max_depth', 10]\n",
        "] \n",
        "\n",
        "Метод оценивания информативности признаков заключается в следующем: ошибку Qn базового дерева bn оценивают по out-of-bag выборке и запоминают. После этого признак j превращают в абсолютно бесполезный, шумовой: в матрицу «объекты-признаки» все значения в столбце j перемешивают. Затем то же самое дерево bn применяют к данной выборке с перемешанным признаком j и оценивают качество дерева на out-of-bag-подвыборке. Q′n — ошибка out-of-bag-подвыборке, она будет тем больше, чем сильнее дерево использует признак j. Если он активно используется в дереве, то ошибка сильно уменьшится, поскольку значение данного признака испорчено. Если же данный признак совершенно не важен для дерева и не используется в нем, то ошибка практически не изменится. Таким образом, информативность признака j оценивают как разность Q ′n − Q n . Далее эти информативности усредняют по всем деревьям случайного леса, и чем больше будет среднее значе- ние, тем важнее признак. На практике оказывается, что информативности, вычисленные описанным образом, и информативности, вычисленные как сумма уменьшения критерия информативности, оказываются очень связаны между собой."
      ],
      "metadata": {
        "id": "F-5MTTshgcv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(RandomForest().get_feature_informativeness(X, y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgSbYoA2gdYF",
        "outputId": "c7d40f23-6918-4120-8b2f-863f99231dd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 4  0  1  5  3  7  9  2  6 10 11 12  8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы получили вектор индексов признаков в порядке убывания их значимости. Таким образом, Balance, Age, NumOfProducts, EstimatedSalary, IsActiveMember являются самыми информативными (5 первых признаков из вектора)."
      ],
      "metadata": {
        "id": "fH298p7mg0S7"
      }
    }
  ]
}